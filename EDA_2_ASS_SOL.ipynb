{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1b8758d-9100-4645-a9fc-4f72686b2b1a",
   "metadata": {
    "id": "f1b8758d-9100-4645-a9fc-4f72686b2b1a"
   },
   "source": [
    "## DATA PREPROCESSING AND FEATURE ENGINEERING IN MACHINE LEARNING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ead5fbd-f9f5-415a-a82e-7203615df791",
   "metadata": {
    "id": "4ead5fbd-f9f5-415a-a82e-7203615df791"
   },
   "source": [
    "### Objective:\n",
    "This assignment aims to equip you with practical skills in data preprocessing, feature engineering, and feature selection techniques, which are crucial for building efficient machine learning models. You will work with a provided dataset to apply various techniques such as scaling, encoding, and feature selection methods including isolation forest and PPS score analysis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "316b3fe9-5855-472e-bdf3-93e81705b237",
   "metadata": {
    "id": "316b3fe9-5855-472e-bdf3-93e81705b237"
   },
   "source": [
    "### Data Exploration and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b20ef7ad-3324-4a10-a791-fcaeced16dee",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b20ef7ad-3324-4a10-a791-fcaeced16dee",
    "outputId": "fb0e1e49-ee41-4379-ea47-9e9ec189eef2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary Statistics:\n",
      "                 age        fnlwgt  education_num  capital_gain  capital_loss  \\\n",
      "count  32561.000000  3.256100e+04   32561.000000  32561.000000  32561.000000   \n",
      "mean      38.581647  1.897784e+05      10.080679   1077.648844     87.303830   \n",
      "std       13.640433  1.055500e+05       2.572720   7385.292085    402.960219   \n",
      "min       17.000000  1.228500e+04       1.000000      0.000000      0.000000   \n",
      "25%       28.000000  1.178270e+05       9.000000      0.000000      0.000000   \n",
      "50%       37.000000  1.783560e+05      10.000000      0.000000      0.000000   \n",
      "75%       48.000000  2.370510e+05      12.000000      0.000000      0.000000   \n",
      "max       90.000000  1.484705e+06      16.000000  99999.000000   4356.000000   \n",
      "\n",
      "       hours_per_week  \n",
      "count    32561.000000  \n",
      "mean        40.437456  \n",
      "std         12.347429  \n",
      "min          1.000000  \n",
      "25%         40.000000  \n",
      "50%         40.000000  \n",
      "75%         45.000000  \n",
      "max         99.000000  \n",
      "\n",
      "Missing Values:\n",
      " age               0\n",
      "workclass         0\n",
      "fnlwgt            0\n",
      "education         0\n",
      "education_num     0\n",
      "marital_status    0\n",
      "occupation        0\n",
      "relationship      0\n",
      "race              0\n",
      "sex               0\n",
      "capital_gain      0\n",
      "capital_loss      0\n",
      "hours_per_week    0\n",
      "native_country    0\n",
      "income            0\n",
      "dtype: int64\n",
      "\n",
      "Data Types:\n",
      " age                int64\n",
      "workclass         object\n",
      "fnlwgt             int64\n",
      "education         object\n",
      "education_num      int64\n",
      "marital_status    object\n",
      "occupation        object\n",
      "relationship      object\n",
      "race              object\n",
      "sex               object\n",
      "capital_gain       int64\n",
      "capital_loss       int64\n",
      "hours_per_week     int64\n",
      "native_country    object\n",
      "income            object\n",
      "dtype: object\n",
      "\n",
      "Standard Scaled Data:\n",
      "         age    fnlwgt  education_num  capital_gain  capital_loss  \\\n",
      "0  0.030671 -1.063611       1.134739      0.148453      -0.21666   \n",
      "1  0.837109 -1.008707       1.134739     -0.145920      -0.21666   \n",
      "2 -0.042642  0.245079      -0.420060     -0.145920      -0.21666   \n",
      "3  1.057047  0.425801      -1.197459     -0.145920      -0.21666   \n",
      "4 -0.775768  1.408176       1.134739     -0.145920      -0.21666   \n",
      "\n",
      "   hours_per_week  \n",
      "0       -0.035429  \n",
      "1       -2.222153  \n",
      "2       -0.035429  \n",
      "3       -0.035429  \n",
      "4       -0.035429  \n",
      "\n",
      "Min-Max Scaled Data:\n",
      "         age    fnlwgt  education_num  capital_gain  capital_loss  \\\n",
      "0  0.301370  0.044302       0.800000       0.02174           0.0   \n",
      "1  0.452055  0.048238       0.800000       0.00000           0.0   \n",
      "2  0.287671  0.138113       0.533333       0.00000           0.0   \n",
      "3  0.493151  0.151068       0.400000       0.00000           0.0   \n",
      "4  0.150685  0.221488       0.800000       0.00000           0.0   \n",
      "\n",
      "   hours_per_week  \n",
      "0        0.397959  \n",
      "1        0.122449  \n",
      "2        0.397959  \n",
      "3        0.397959  \n",
      "4        0.397959  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "\n",
    "\n",
    "# Load dataset\n",
    "data = pd.read_csv(r\"https://raw.githubusercontent.com/rohitmaind/ExcelR_Assignments/main/Datasets/adult_with_headers.csv\")\n",
    "\n",
    "# Basic data exploration\n",
    "print(\"Summary Statistics:\\n\", data.describe())\n",
    "print(\"\\nMissing Values:\\n\", data.isnull().sum())\n",
    "print(\"\\nData Types:\\n\", data.dtypes)\n",
    "\n",
    "# Handle missing values\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "data['age'] = imputer.fit_transform(data[['age']])\n",
    "\n",
    "# Apply scaling techniques\n",
    "scaler_standard = StandardScaler()\n",
    "data_standard_scaled = pd.DataFrame(scaler_standard.fit_transform(data.select_dtypes(include=[np.number])), columns=data.select_dtypes(include=[np.number]).columns)\n",
    "\n",
    "scaler_minmax = MinMaxScaler()\n",
    "data_minmax_scaled = pd.DataFrame(scaler_minmax.fit_transform(data.select_dtypes(include=[np.number])), columns=data.select_dtypes(include=[np.number]).columns)\n",
    "\n",
    "# Display scaled data\n",
    "print(\"\\nStandard Scaled Data:\\n\", data_standard_scaled.head())\n",
    "print(\"\\nMin-Max Scaled Data:\\n\", data_minmax_scaled.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e142c6-e1e5-4ce9-a513-9ec37d4f8b1c",
   "metadata": {
    "id": "28e142c6-e1e5-4ce9-a513-9ec37d4f8b1c"
   },
   "source": [
    "### Encoding Techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "acaa5a3d-f3ff-44f1-8d8b-dffb5b007505",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "acaa5a3d-f3ff-44f1-8d8b-dffb5b007505",
    "outputId": "d5295079-2ef2-4e3b-813e-239dd3257144"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    age  workclass  fnlwgt  education  education_num  marital_status  \\\n",
      "0  39.0          7   77516          9             13               4   \n",
      "1  50.0          6   83311          9             13               2   \n",
      "2  38.0          4  215646         11              9               0   \n",
      "3  53.0          4  234721          1              7               2   \n",
      "4  28.0          4  338409          9             13               2   \n",
      "\n",
      "   occupation  relationship  race  capital_gain  capital_loss  hours_per_week  \\\n",
      "0           1             1     4          2174             0              40   \n",
      "1           4             0     4             0             0              13   \n",
      "2           6             1     4             0             0              40   \n",
      "3           6             0     2             0             0              40   \n",
      "4          10             5     2             0             0              40   \n",
      "\n",
      "   native_country  sex_ Male  income_ >50K  \n",
      "0              39        1.0           0.0  \n",
      "1              39        1.0           0.0  \n",
      "2              39        1.0           0.0  \n",
      "3              39        1.0           0.0  \n",
      "4               5        0.0           0.0  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "\n",
    "# Select categorical columns\n",
    "categorical_columns = data.select_dtypes(include=['object']).columns\n",
    "\n",
    "# One-Hot Encoding for categorical variables with less than 5 categories\n",
    "one_hot_encoder = OneHotEncoder(drop='first', sparse_output=False)\n",
    "categorical_small = [col for col in categorical_columns if data[col].nunique() < 5]\n",
    "data_one_hot_encoded = pd.DataFrame(one_hot_encoder.fit_transform(data[categorical_small]), columns=one_hot_encoder.get_feature_names_out(categorical_small))\n",
    "\n",
    "# Label Encoding for categorical variables with more than 5 categories\n",
    "label_encoder = LabelEncoder()\n",
    "categorical_large = [col for col in categorical_columns if data[col].nunique() >= 5]\n",
    "\n",
    "for col in categorical_large:\n",
    "    data[col] = label_encoder.fit_transform(data[col])\n",
    "\n",
    "# Merge the one-hot encoded columns back to the original dataframe\n",
    "data = data.drop(columns=categorical_small)\n",
    "data = pd.concat([data, data_one_hot_encoded], axis=1)\n",
    "\n",
    "# Display the first few rows of the transformed dataframe\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9023ae9-78e7-411a-b5be-61ca4fc81f49",
   "metadata": {
    "id": "f9023ae9-78e7-411a-b5be-61ca4fc81f49"
   },
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4786d407-951b-4da6-b45d-3affb562a9ca",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4786d407-951b-4da6-b45d-3affb562a9ca",
    "outputId": "4acca387-7e1a-4311-f70a-d2f6d47381b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New Features:\n",
      "      age_group  capital_gain_loss  capital_gain_log\n",
      "0        Adult               2174          7.684784\n",
      "1  Middle-Aged                  0          0.000000\n",
      "2        Adult                  0          0.000000\n",
      "3  Middle-Aged                  0          0.000000\n",
      "4        Adult                  0          0.000000\n"
     ]
    }
   ],
   "source": [
    "# Creating new features\n",
    "data['age_group'] = pd.cut(data['age'], bins=[0, 25, 45, 65, np.inf], labels=['Young', 'Adult', 'Middle-Aged', 'Senior'])\n",
    "data['capital_gain_loss'] = data['capital_gain'] - data['capital_loss']\n",
    "\n",
    "# Log transformation for skewed numerical feature\n",
    "data['capital_gain_log'] = np.log1p(data['capital_gain'])\n",
    "\n",
    "# Display new features\n",
    "print(\"\\nNew Features:\\n\", data[['age_group', 'capital_gain_loss', 'capital_gain_log']].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9da838f-a2f3-4fc2-b563-349ab1e93f4a",
   "metadata": {
    "id": "c9da838f-a2f3-4fc2-b563-349ab1e93f4a"
   },
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "84a88459-b9b2-40f2-bfef-107c199e02c8",
   "metadata": {
    "id": "84a88459-b9b2-40f2-bfef-107c199e02c8"
   },
   "outputs": [],
   "source": [
    "#!pip install --upgrade pip\n",
    "\n",
    "#!pip install --upgrade pandas\n",
    "#!pip install ppscore\n",
    "#import ppscore as pps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "30374c6e-8b2a-4cbb-91f3-ebc6893ec5cf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "30374c6e-8b2a-4cbb-91f3-ebc6893ec5cf",
    "outputId": "5e801a1e-d069-4e56-a6f8-fecf64c709f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data without Outliers:\n",
      "     age  workclass  fnlwgt  education  education_num  marital_status  \\\n",
      "0  39.0          7   77516          9             13               4   \n",
      "1  50.0          6   83311          9             13               2   \n",
      "2  38.0          4  215646         11              9               0   \n",
      "3  53.0          4  234721          1              7               2   \n",
      "4  28.0          4  338409          9             13               2   \n",
      "\n",
      "   occupation  relationship  race  capital_gain  capital_loss  hours_per_week  \\\n",
      "0           1             1     4          2174             0              40   \n",
      "1           4             0     4             0             0              13   \n",
      "2           6             1     4             0             0              40   \n",
      "3           6             0     2             0             0              40   \n",
      "4          10             5     2             0             0              40   \n",
      "\n",
      "   native_country  sex_ Male  income_ >50K    age_group  capital_gain_loss  \\\n",
      "0              39        1.0           0.0        Adult               2174   \n",
      "1              39        1.0           0.0  Middle-Aged                  0   \n",
      "2              39        1.0           0.0        Adult                  0   \n",
      "3              39        1.0           0.0  Middle-Aged                  0   \n",
      "4               5        0.0           0.0        Adult                  0   \n",
      "\n",
      "   capital_gain_log  outliers  \n",
      "0          7.684784         1  \n",
      "1          0.000000         1  \n",
      "2          0.000000         1  \n",
      "3          0.000000         1  \n",
      "4          0.000000         1  \n",
      "\n",
      "PPS Matrix:\n",
      "             x                  y  ppscore            case  is_valid_score  \\\n",
      "0         age                age      1.0  predict_itself            True   \n",
      "1         age          workclass      0.0      regression            True   \n",
      "2         age             fnlwgt      0.0      regression            True   \n",
      "3         age          education      0.0      regression            True   \n",
      "4         age      education_num      0.0      regression            True   \n",
      "..        ...                ...      ...             ...             ...   \n",
      "356  outliers       income_ >50K      0.0      regression            True   \n",
      "357  outliers          age_group      0.0  classification            True   \n",
      "358  outliers  capital_gain_loss      0.0      regression            True   \n",
      "359  outliers   capital_gain_log      0.0      regression            True   \n",
      "360  outliers           outliers      1.0  predict_itself            True   \n",
      "\n",
      "                  metric  baseline_score   model_score  \\\n",
      "0                   None        0.000000      1.000000   \n",
      "1    mean absolute error        0.686800      0.804634   \n",
      "2    mean absolute error    74578.118200  75656.712242   \n",
      "3    mean absolute error        2.595000      2.622791   \n",
      "4    mean absolute error        1.760600      1.803835   \n",
      "..                   ...             ...           ...   \n",
      "356  mean absolute error        0.214200      0.336720   \n",
      "357          weighted F1        0.359000      0.346751   \n",
      "358  mean absolute error      270.467200    441.996613   \n",
      "359  mean absolute error        0.386351      0.737310   \n",
      "360                 None        0.000000      1.000000   \n",
      "\n",
      "                        model  \n",
      "0                        None  \n",
      "1     DecisionTreeRegressor()  \n",
      "2     DecisionTreeRegressor()  \n",
      "3     DecisionTreeRegressor()  \n",
      "4     DecisionTreeRegressor()  \n",
      "..                        ...  \n",
      "356   DecisionTreeRegressor()  \n",
      "357  DecisionTreeClassifier()  \n",
      "358   DecisionTreeRegressor()  \n",
      "359   DecisionTreeRegressor()  \n",
      "360                      None  \n",
      "\n",
      "[361 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "# Using Isolation Forest to identify outliers\n",
    "isolation_forest = IsolationForest(contamination=0.1)\n",
    "outliers = isolation_forest.fit_predict(data.select_dtypes(include=[np.number]))\n",
    "data['outliers'] = outliers\n",
    "data_no_outliers = data[data['outliers'] == 1]\n",
    "\n",
    "# Display data without outliers\n",
    "print(\"\\nData without Outliers:\\n\", data_no_outliers.head())\n",
    "\n",
    "# PPS score analysis\n",
    "pps_matrix = pps.matrix(data_no_outliers)\n",
    "\n",
    "# Display PPS matrix\n",
    "print(\"\\nPPS Matrix:\\n\", pps_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb588df-fccc-40fd-aced-16966eb307a4",
   "metadata": {
    "id": "6eb588df-fccc-40fd-aced-16966eb307a4"
   },
   "source": [
    "###  Conclusion\n",
    "\n",
    "In this assignment, we focused on essential steps for preparing the \"Adult\" dataset for machine learning:\n",
    "\n",
    "1. **Data Exploration and Preprocessing**:\n",
    "   - **Summary Statistics & Missing Values**: Conducted basic exploration and handled missing values using mean imputation.\n",
    "   - **Scaling**:\n",
    "     - **Standard Scaling**: Preferred for normally distributed data.\n",
    "     - **Min-Max Scaling**: Useful for preserving original data distribution.\n",
    "\n",
    "2. **Encoding Techniques**:\n",
    "   - **One-Hot Encoding**: Used for categorical variables with fewer than 5 categories to avoid ordinal relationships.\n",
    "   - **Label Encoding**: Applied to categorical variables with more than 5 categories for simplicity.\n",
    "\n",
    "3. **Feature Engineering**:\n",
    "   - Created two new features and applied log transformation to a skewed numerical feature to normalize its distribution.\n",
    "\n",
    "4. **Feature Selection**:\n",
    "   - **Isolation Forest**: Identified and removed outliers to improve model performance.\n",
    "   - **PPS Score**: Analyzed relationships between features, providing a more nuanced view than the correlation matrix.\n",
    "\n",
    "These preprocessing steps are crucial for building effective and efficient machine learning models, ensuring the data is clean, well-scaled, and features are appropriately engineered and selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724435d0-ba81-4194-b885-a5eaf1b2d5e1",
   "metadata": {
    "id": "724435d0-ba81-4194-b885-a5eaf1b2d5e1"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b1a928-038b-448e-8905-edcdf285b0cb",
   "metadata": {
    "id": "d0b1a928-038b-448e-8905-edcdf285b0cb"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "6eb588df-fccc-40fd-aced-16966eb307a4"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
